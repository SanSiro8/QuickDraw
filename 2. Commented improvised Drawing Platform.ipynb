{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff818e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3.dev8 (SDL 2.0.22, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import cairocffi as cairo\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Diese zwei funktionen müssen definiert werden, damit das Programm laufen kann\n",
    "# Die Funktionen hier wurden jedoch schon zuvor erklärt\n",
    "class MyDataset(Dataset):\n",
    "            def __init__(self, images, labels):\n",
    "                self.images = images\n",
    "                self.labels = labels\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                image = self.images[index]\n",
    "                label = self.labels[index]\n",
    "                return image, label\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.images)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Define the max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=576, out_features=128) #64, 128\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "        # Define the activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Flatten the output of the convolutional layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Apply the fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Apply the softmax function\n",
    "        x = self.softmax(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "cnn = CNN(num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Predicted class label: 2\n",
      "Predicted class name: backpack.npy\n"
     ]
    }
   ],
   "source": [
    "# Initialisiere Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Window grösse festlegen\n",
    "window_size = (800, 600)\n",
    "\n",
    "# Ein Window erstellen\n",
    "window = pygame.display.set_mode(window_size)\n",
    "\n",
    "# Diesem Window einen Titel geben\n",
    "pygame.display.set_caption(\"Drawing Window for QuickDraw\")\n",
    "\n",
    "# Den Font für den Text auswählen\n",
    "font = pygame.font.Font(None, 30)\n",
    "\n",
    "# Mein zuvor kreiirtes Text-Dokument (Code im Ordner) öffnen\n",
    "with open(\"categories.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Den Text darstellen\n",
    "text_surface = font.render(text, True, (255, 255, 255))\n",
    "\n",
    "# Hintergrund Farbe festlegen\n",
    "window.fill((255, 255, 255))\n",
    "\n",
    "# Den Text auf Linien aufteilen\n",
    "lines = text.split(\"\\n\")\n",
    "\n",
    "# Die Startposition festlegen\n",
    "scroll_pos = 0\n",
    "\n",
    "# Eine Verzögerung für das Scrollen festlegen\n",
    "delay = 50\n",
    "\n",
    "# Haupt Schleife\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        # Hier wird das Programm abgebrochen, für den Fall, das Quit geklickt wird\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "    # Das scrollen wird hier beschrieben            \n",
    "    keys = pygame.key.get_pressed()\n",
    "    if keys[pygame.K_UP]:\n",
    "        scroll_pos -= 1\n",
    "    if keys[pygame.K_DOWN]:\n",
    "        scroll_pos += 1\n",
    "\n",
    "    # Den Bildschirm löschen\n",
    "    window.fill((255, 255, 255))\n",
    "    \n",
    "    # Den Text anzeigen\n",
    "    for i, line in enumerate(lines[scroll_pos:]):\n",
    "        text_surface = font.render(line, True, (0, 0, 0))\n",
    "        window.blit(text_surface, (50, 50 + (i * 30)))\n",
    "    \n",
    "    # Den Bildschirm Updaten\n",
    "    pygame.display.flip()\n",
    "    \n",
    "    pygame.time.wait(delay)\n",
    "    \n",
    "# Pygame schliessen   \n",
    "pygame.quit()\n",
    "\n",
    "pygame.init()\n",
    "window_size = (800, 600)\n",
    "screen = pygame.display.set_mode(window_size)\n",
    "pygame.display.set_caption(\"User Input Example\")\n",
    "font = pygame.font.Font(None, 30)\n",
    "\n",
    "# Variable um den Text des Users zu speichern\n",
    "user_text = \"\"\n",
    "\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            # Nutzereingaben nutzen\n",
    "            if event.unicode.isprintable():\n",
    "                user_text += event.unicode\n",
    "            elif event.key == pygame.K_BACKSPACE:\n",
    "                user_text = user_text[:-1]\n",
    "\n",
    "    screen.fill((255, 255, 255))\n",
    "\n",
    "    # Den Text Anzeigen\n",
    "    prompt_text = \"Please enter your wished category here:\"\n",
    "    prompt_surface = font.render(prompt_text, True, (0, 0, 0))\n",
    "    screen.blit(prompt_surface, (50, 50))\n",
    "\n",
    "    # Das Textfeld anzeigen\n",
    "    text_field_surface = font.render(user_text, True, (0, 0, 0))\n",
    "    screen.blit(text_field_surface, (50, 100))\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Die Eingabe drucken\n",
    "print(user_text)\n",
    "\n",
    "pygame.quit()\n",
    "\n",
    "\"\"\"\n",
    "pygame.init()\n",
    "window_size = (800, 600)\n",
    "#window = pygame.display.set_mode(window_size, pygame.HWSURFACE | pygame.DOUBLEBUF | pygame.RESIZABLE)\n",
    "window = pygame.display.set_mode(window_size)\n",
    "window.fill((255, 255, 255))\n",
    "pixel_surface = pygame.Surface((28, 28))\n",
    "#pixel_surface.fill((255, 255, 255))\n",
    "#pygame.draw.rect(pixel_surface, (255, 0, 0), (5, 5, 18, 18))\n",
    "#scaled_surface = pygame.Surface.convert(pixel_surface)\n",
    "#scaled_surface = pygame.Surface.set_scale(scaled_surface, 8)\n",
    "#scaled_surface = pygame.transform.scale(pixel_surface, (28*8, 28*8))\n",
    "#window.blit(pixel_surface, (236, 236))\n",
    "window.blit(pygame.transform.scale(pixel_surface, window_size), (0,0))\n",
    "pygame.display.set_caption(\"Drawing Window for QuickDraw\")\n",
    "font = pygame.font.Font(None, 30)\n",
    "text_surface = font.render(text, True, (255, 255, 255))\n",
    "window.fill((255, 255, 255))\n",
    "pygame.display.flip()\n",
    "\n",
    "running = True\n",
    "drawing = False\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        # Für den Fall des schliessen des Programmes\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        \n",
    "        # Umgang mit Maustaste unten (beginn zu zeichnen)\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            drawing = True\n",
    "            last_pos = event.pos\n",
    "        \n",
    "        # Umgang mit Maustaste Oben (Stop das Zeichnen)\n",
    "        elif event.type == pygame.MOUSEBUTTONUP:\n",
    "            drawing = False\n",
    "        \n",
    "        # Umgang mit Mausbewegungen (Linie zeichnen)\n",
    "        elif event.type == pygame.MOUSEMOTION:\n",
    "            if drawing:\n",
    "                pygame.draw.line(window, (0, 0, 0), last_pos, event.pos, 5)\n",
    "                #pygame.draw.line(scaled_surface, (0, 0, 0), last_pos, event.pos, 5)\n",
    "                last_pos = event.pos\n",
    "    \n",
    "    # Gedruckte Tasten\n",
    "    keys = pygame.key.get_pressed()\n",
    "    if keys[pygame.K_s]:\n",
    "        # Das Bild als JPG speichern\n",
    "        rgb_image = window.convert()\n",
    "        pygame.image.save(rgb_image, \"drawing_28x28.jpg\")\n",
    "\n",
    "    # Der Bildschirm updaten\n",
    "    pygame.display.update()\n",
    "\n",
    "pygame.quit()\n",
    "\"\"\"\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set the dimensions of the screen (width, height).\n",
    "size = (300, 300)\n",
    "window = pygame.display.set_mode(size)\n",
    "\n",
    "# Set the title of the window\n",
    "pygame.display.set_caption(\"28x28 Pixel Screen\")\n",
    "\n",
    "# Create a 28x28 pixel surface\n",
    "pixel_surface = pygame.Surface((112, 112))\n",
    "\n",
    "# Fill the surface with white color\n",
    "pixel_surface.fill((255, 255, 255))\n",
    "\n",
    "ratio_w = size[0]/28\n",
    "ratio_h = size[1]/28\n",
    "\n",
    "running = True\n",
    "drawing = False\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        \n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            drawing = True\n",
    "            last_pos = (event.pos)\n",
    "            pygame.draw.circle(pixel_surface, (0, 0, 0), (int(event.pos[0]/ratio_w), int(event.pos[1]/ratio_h)),1)\n",
    "            \n",
    "        elif event.type == pygame.MOUSEBUTTONUP:\n",
    "            drawing = False\n",
    "            \n",
    "        elif event.type == pygame.MOUSEMOTION:\n",
    "            if drawing:\n",
    "                pygame.draw.circle(pixel_surface, (0, 0, 0), (int(event.pos[0]/ratio_w), int(event.pos[1]/ratio_h)),1)\n",
    "                \n",
    "    window.fill((255,255,255))\n",
    "    window.blit(pygame.transform.scale(pixel_surface, size), (0, 0))\n",
    "    keys = pygame.key.get_pressed()\n",
    "    if keys[pygame.K_s]:\n",
    "        # Das Bild als JPG speichern\n",
    "        rgb_image = window.convert()\n",
    "        pygame.image.save(rgb_image, \"drawing.jpg\")\n",
    "\n",
    "    pygame.display.update()\n",
    "\n",
    "pygame.quit()\n",
    "\n",
    "# Um richtige Klassifikation zu garantieren, müsste ich eine möglichkeit haben mein JPG durch diese Funktion zu geben\n",
    "# Diese Funktion würde das Bild in ein, für das CNN vertrautes Bild verwandeln\n",
    "# Die orginale Eingabe für diesen Code wären .bit files, welche Striche als Vektor gespeichert haben\n",
    "# Mit diesem Schritt hier hatte ich viele schwierigkeiten, jedoch war es schlussendlich einfach die Zeit welche fehlte\n",
    "# Die Funktion vector_to_raster wurde auch verwendet, um die orginalen Daten herzustellen und ist auch auf der Datenseite zu finden\n",
    "\"\"\"# Load the image from .npy file\n",
    "img = np.load(\"drawing.npy\")\n",
    "\n",
    "print(img.shape)\n",
    "# if necessary Convert to grayscale\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "# Apply Gaussian Blur to reduce noise\n",
    "img = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "# Apply Canny Edge Detection\n",
    "edges = cv2.Canny(img, 50, 150)\n",
    "\n",
    "# Find lines using HoughLinesP\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=50, maxLineGap=5)\n",
    "\n",
    "# Extract x,y coordinates of the lines\n",
    "lines_coordinates = [[(line[0][0], line[0][1]), (line[0][2], line[0][3])] for line in lines]\n",
    "\n",
    "\n",
    "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)): #vector_images\n",
    "    \n",
    "    padding and line_diameter are relative to the original 256x256 image.\n",
    "    \n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        vector_image = np.array(vector_image)\n",
    "        print(type(vector_image))\n",
    "        print(vector_image.shape)\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        #vector_image = np.concatenate(vector_image)\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=0)\n",
    "        #bbox = np.concatenate(vector_image)\n",
    "        print(bbox.shape)\n",
    "        print(bbox)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "\n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images\n",
    "\n",
    "data = vector_to_raster(vector_images= lines_coordinates)\n",
    "\"\"\"\n",
    "# Dies ist der Weg zu dem vorher gespeicherten Bild\n",
    "path = 'drawing.jpg'\n",
    "# Das Bild öffnen\n",
    "image = Image.open(path).convert('L')\n",
    "# Hier könnte man sich das orginal anzeigen lassen\n",
    "image.show()\n",
    "# Das Bild verkleinern\n",
    "image = image.resize((28, 28))\n",
    "# Hier könnte man sich das verwandelte Bild anzeigen lassen\n",
    "image.show()\n",
    "# Hier speichern wir das verkleinerte Bild als JPG und als NPY\n",
    "image.save('drawing_28x28.jpg')\n",
    "np.save('drawing.npy', image)\n",
    "\n",
    "# Hier öffnen wir die verschiedenen Textdateien mit den Labels der Daten\n",
    "# Diese .txt Daten wurden auch mit einem Code in dem Ordner generiert und gespeichert\n",
    "# Die Datei wird aufgrund der zuvorigen Nutzereingabe ausgewählt\n",
    "with open(\"Categories_Text/{}.txt\".format(user_text), \"r\") as f:\n",
    "    class_labels = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "\n",
    "# Hier laden wir unser CNN und schieben es auf die CPU\n",
    "# Dies tun wir, da es nur ein Bild ist und man dies nicht auf einer GPU berechnen muss\n",
    "# Diese Datei wird auch durch die vorherige Nutzereingabe bestimmt\n",
    "state_dict = torch.load('cnn_{}.pt'.format(user_text), map_location='cpu')\n",
    "\n",
    "# Denn Model Status festlegen\n",
    "cnn.load_state_dict(state_dict)\n",
    "# Das model von training zu evaltuation setzen\n",
    "cnn.eval()\n",
    "\n",
    "#Die Daten laden\n",
    "data = np.load(\"drawing.npy\")\n",
    "# Das Bild zu einem Tensor verwandeln\n",
    "input_tensor = torch.from_numpy(data)\n",
    "# Die Daten zu float verwandeln\n",
    "input_tensor = input_tensor.float() \n",
    "\n",
    "# Den Tensor umformen um den erwarteten Eingaben des Models zu entsprechen\n",
    "input_tensor = input_tensor.reshape((1, 1, 28, 28))\n",
    "\n",
    "# Ohne das Model zu trainieren, wird das Bild durch das Model gebracht\n",
    "with torch.no_grad():\n",
    "    output = cnn(input_tensor)\n",
    "    \n",
    "# Nun entnehmen wir dem Model die Klasse mit der höchsten Wahrscheinlichkeit\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "\n",
    "# Jetzt nehmen wir das Label der vorhergesagten Klasse\n",
    "predicted_class_label = predicted.item()\n",
    "\n",
    "# Nun drucken wir die Klasse und das Label\n",
    "print(\"Predicted class label:\", predicted_class_label)\n",
    "print(\"Predicted class name:\", class_labels[predicted_class_label])\n",
    "\n",
    "\n",
    "pygame.init()\n",
    "size = (800, 600)\n",
    "screen = pygame.display.set_mode(size)\n",
    "screen.fill((255, 255, 255))\n",
    "pygame.display.set_caption(\"Prediction Result\")\n",
    "\n",
    "# Den Text anzeigen\n",
    "font = pygame.font.Font(None, 32)\n",
    "text = font.render(\"Predicted class label: {}\".format(predicted_class_label), True, (0, 0, 0))\n",
    "text2 = font.render(\"Predicted class name: {}\".format(class_labels[predicted_class_label]), True, (0, 0, 0))\n",
    "screen.blit(text, (50, 100))\n",
    "screen.blit(text2, (50, 150))\n",
    "pygame.display.flip()\n",
    "\n",
    "# Die Pygame Schlaufe\n",
    "running = True\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "# Exit Pygame\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da3a57d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b19ad627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the image from .npy file\\nimg = np.load(\"drawing.npy\")\\n\\nprint(img.shape)\\n# if necessary Convert to grayscale\\n#img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\\nimg = img.astype(np.uint8)\\n\\n# Apply Gaussian Blur to reduce noise\\nimg = cv2.GaussianBlur(img, (5,5), 0)\\n\\n# Apply Canny Edge Detection\\nedges = cv2.Canny(img, 50, 150)\\n\\n# Find lines using HoughLinesP\\nlines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=50, maxLineGap=5)\\n\\n# Extract x,y coordinates of the lines\\nlines_coordinates = [[(line[0][0], line[0][1]), (line[0][2], line[0][3])] for line in lines]\\n\\n\\ndef vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)): #vector_images\\n    \\n    padding and line_diameter are relative to the original 256x256 image.\\n    \\n    \\n    original_side = 256.\\n    \\n    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\\n    ctx = cairo.Context(surface)\\n    ctx.set_antialias(cairo.ANTIALIAS_BEST)\\n    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\\n    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\\n    ctx.set_line_width(line_diameter)\\n\\n    # scale to match the new size\\n    # add padding at the edges for the line_diameter\\n    # and add additional padding to account for antialiasing\\n    total_padding = padding * 2. + line_diameter\\n    new_scale = float(side) / float(original_side + total_padding)\\n    ctx.scale(new_scale, new_scale)\\n    ctx.translate(total_padding / 2., total_padding / 2.)\\n\\n    raster_images = []\\n    for vector_image in vector_images:\\n        vector_image = np.array(vector_image)\\n        print(type(vector_image))\\n        print(vector_image.shape)\\n        # clear background\\n        ctx.set_source_rgb(*bg_color)\\n        ctx.paint()\\n        #vector_image = np.concatenate(vector_image)\\n        \\n        bbox = np.hstack(vector_image).max(axis=0)\\n        #bbox = np.concatenate(vector_image)\\n        print(bbox.shape)\\n        print(bbox)\\n        offset = ((original_side, original_side) - bbox) / 2.\\n        offset = offset.reshape(-1,1)\\n        centered = [stroke + offset for stroke in vector_image]\\n\\n        # draw strokes, this is the most cpu-intensive part\\n        ctx.set_source_rgb(*fg_color)        \\n        for xv, yv in centered:\\n            ctx.move_to(xv[0], yv[0])\\n            for x, y in zip(xv, yv):\\n                ctx.line_to(x, y)\\n            ctx.stroke()\\n\\n        data = surface.get_data()\\n        raster_image = np.copy(np.asarray(data)[::4])\\n        raster_images.append(raster_image)\\n    \\n    return raster_images\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b003ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "torch.Size([28, 28])\n",
      "Predicted class label: 3\n",
      "Predicted class name: banana.npy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24ad4e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict(model,img,label_dict)\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf463b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
